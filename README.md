![alt text](系统框架.PNG)

# 告警研判侧

## 告警日志获取

根据业务需求设定时间间隔，定期从Elasticsearch中获取告警日志，告警日志的格式为json。由于一次查询可能获取到大量数据，因此需要对数据进行分批处理。将对应的文件名命名为“告警日志_时间戳”，并存储到本地指定目录，同时传入到kafka消息队列中，使研判过程与日志获取过程解耦和异步进行。

### 输入

- 无直接输入，触发条件为定时任务。

### 处理

1.  连接Elasticsearch。
2.  根据预设查询条件和时间窗口获取告警日志（JSON格式）。
3.  对获取的大量日志进行分批处理。
4.  将每批日志保存为本地文件（命名格式：“告警日志_时间戳.json”）。
5.  将日志文件名或日志内容发送到Kafka指定主题（Topic）。

### 输出

- 本地存储的原始告警日志文件。
- 发送到Kafka的原始告警日志消息。

## 告警白名单模块

### 输入

- Kafka消息队列中的原始告警日志。
- 告警白名单规则（存储在Redis中）。

*代码实现*: 日志通过 `alert analysis/load_data_new.py` 中的 `read_log_file` 函数读取并解析为 `LogEntry` 对象列表。

### 处理

1.  消费Kafka中的原始告警日志消息。
2.  加载告警白名单规则。
3.  逐条比对告警日志与白名单规则。
4.  过滤掉命中白名单规则的告警。

*代码实现*: 使用 `wlredis.py` 中的 `WhitelistManager` 类和 `filter_by_whitelist` 函数。系统检查每个 `LogEntry` 的六元组信息（日志类型、源/目的IP、源/目的端口、攻击类型）是否存在于 Redis 维护的白名单中。白名单可通过 `api.py` 中的 API 进行管理。

### 输出

- 未命中白名单的告警日志集合（`告警集合1`），传递给告警过滤模块（例如，发送到另一个Kafka主题）。

*数据结构*: `告警集合1` 是经过白名单过滤后的 `LogEntry` 对象列表。在 `alert analysis/process_data.py` 中对应调用 `filter_by_whitelist` 后的 `filter_log_entries` 列表。

## 告警过滤模块

### 输入

- 告警白名单模块输出的告警日志集合（`告警集合1`）。

### 处理

1.  **告警标准化**: 统一告警日志的格式或关键字段。
    *   *代码实现*: 在 `read_log_file` 读取时完成，将不同来源的日志统一为 `LogEntry` 格式。
2.  **时间窗口去重**: 在指定时间窗口内，去除重复或高度相似的告警。
    *   *代码实现*: 调用 `alert analysis/filter_by_time.py` 中的 `time_deduplicate` 函数，移除短时间内（如10秒）出现的具有相同关键信息（SIP, DIP, Attack Type, Sport, Dport）的重复告警。
3.  **特殊类型告警筛选**: 根据规则筛选出特定类型的告警（例如，仅保留安全相关告警）。
    *   *代码实现*: 调用 `alert analysis/filter_by_attacktype.py` 中的 `filter_by_attack_type` 函数，根据 `alert analysis/process_data.py` 中定义的 `filters` 规则，过滤掉特定日志类型下的特定攻击类型。
4.  **攻击成功告警筛选**: 根据规则筛选出表示攻击成功的告警。
5.  **告警聚合**: 将关联性强、可归并的告警聚合成一条，减少冗余。
    *   *代码实现*: 调用 `alert analysis/aggregate_alerts.py` 中的 `update_aggregated_alerts` 函数。将经过上述过滤步骤的告警，按照关键信息（sip, dip, log_type, attack_type）进行分组，聚合成 `AggregatedAlert` 对象。每个 `AggregatedAlert` 记录了该组告警的最早/最晚时间、原始告警ID列表 (`ids`) 等信息。

### 输出

- 经过过滤和聚合处理后的告警日志集合（`告警集合2`），传递给大模型研判模块。

*数据结构*: `告警集合2` 是经过过滤和聚合后的告警数据。在 `alert analysis/process_data.py` 中对应 `aggregated_alerts` 字典，其值是 `AggregatedAlert` 对象。后续通常会通过 `AggregatedAlert.to_dict` 方法转换为字典列表用于存储或传输。

## 大模型研判模块

### 输入

- 告警过滤模块输出的告警日志集合（`告警集合2`）。
- 告警模板库。
- 安全知识语料库。
- 预设的自定义规则。
- （可选）用于模型微调和提示工程的方法配置。

*数据流*: `告警集合2` (`aggregated_alerts`) 本身不直接输入大模型。而是，对于集合中的每一个聚合告警项 (`AggregatedAlert`)：
1.  系统根据其 `ids` 列表找到关联的原始告警 (`LogEntry`)。
2.  从原始告警中提取文本字段。
3.  将文本字段构造成 Prompt。
4.  Prompt 发送给大模型进行推理。
5.  将大模型返回的评分写回聚合告警项的 `llm_score` 字段。

### 处理

1.  利用告警模板和安全知识语料库，结合微调和提示词工程方法，准备模型输入。
2.  使用**大模型语义评价模型**对告警进行语义层面的分析和评估。
3.  使用**信息熵评价模型**评估告警信息的不确定性或信息量。
4.  使用**自定义规则评价模型**根据预设规则进行匹配和评估。
5.  综合三个模型的评价结果，对告警进行最终研判。

### 输出

- **研判结果**:
    - `真实告警`：判定为真实有效的告警。
    - `误报`：判定为误报的告警（此结果可用于反馈模块，优化白名单或过滤规则）。
    - `无法研判`：模型无法给出明确判断的告警。
- **告警威胁度评分**: 对判定为`真实告警`的告警进行威胁程度量化评分。

### 大模型语义评价模型详细流程

1.  **接收输入**:
    *   `aggregated_alerts` 字典 (来自 `alert analysis/process_data.py`)，其值为 `AggregatedAlert` 对象列表。
    *   访问原始 `LogEntry` 数据的能力 (通过 Redis 缓存、内存或其他方式，根据 `AggregatedAlert.ids` 查询)。
    *   访问预定义的“告警模板”和“安全知识库”的能力。
    *   **遍历聚合告警**: 迭代 `aggregated_alerts` 字典中的每一个 `AggregatedAlert` 对象。

2.  **准备大模型输入 (Prompt 构建)**:
    *   **获取原始日志**: 对于当前的 `AggregatedAlert`，使用其 `ids` 列表从原始数据源检索对应的 `LogEntry` 对象 (可选择代表性日志)。
    *   **提取关键信息**: 从选定的 `LogEntry` 中提取文本信息，如 `attack_type`, `req_header`, `req_body`, `packet_data` (可能截断), `log_type` 等。
    *   **构建 Prompt**:
        *   **任务描述**: 清晰说明任务 (例如：“评估安全告警风险等级，判断真实攻击可能性，评分0-100”)。
        *   **告警信息**: 格式化提取的关键文本信息。
            ```
            告警类型: [attack_type]
            日志来源: [log_type]
            请求头: [req_header]
            请求体: [req_body]
            原始数据片段: [packet_data snippet]
            ```
        *   **(可选) 补充上下文**: 加入 `attack_type` 的标准描述、模板或相关安全知识。
        *   **输出格式要求**: 明确要求输出格式 (例如：“仅输出评分数字” 或 JSON 格式)。

3.  **调用大模型 API**:
    *   将构建好的 Prompt 发送给大语言模型推理服务 (如通过 HTTP API)。
    *   处理 API 调用错误 (网络、超时、认证等)。

4.  **解析模型输出**:
    *   接收并解析模型响应，提取评分数值。
    *   处理非预期格式或无法评分的情况 (设置默认分或标记)。

5.  **更新分数**:
    *   将解析出的评分更新到当前 `AggregatedAlert` 对象的 `llm_score` 字段。

6.  **循环与输出**:
    *   处理下一个 `AggregatedAlert`，直至全部完成。
    *   输出更新了 `llm_score` 的 `aggregated_alerts`。

7.  **其他考虑**:
    *   **模块化**: 封装 LLM 调用逻辑。
    *   **异步处理**: 使用 `asyncio` 等并发调用 LLM API 以提高效率。
    *   **配置化**: 管理 LLM API 地址、认证、Prompt 模板等配置。
    *   **缓存**: 缓存相同输入的 LLM 评分结果。
    *   **错误处理与重试**: 实现 API 调用重试机制并记录失败。